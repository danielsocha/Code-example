{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Project 3 \u2014 API ETL (Raw Snapshot \u2192 Clean \u2192 Report)\n\n**Audience:** Technical team\n\nThis notebook demonstrates a lightweight extraction pipeline:\n- Extract from a public API\n- Persist a raw snapshot for reproducibility (raw zone)\n- Transform/clean into an analysis-ready DataFrame\n- Produce a small report\n\nIncludes a local fallback dataset to keep the notebook runnable even without internet access."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import requests\nimport pandas as pd\nimport json\nfrom pathlib import Path\nfrom datetime import datetime"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "API_URL = \"https://jsonplaceholder.typicode.com/posts\"\nRAW_DIR = Path(\"raw_zone\")\nRAW_DIR.mkdir(exist_ok=True)\n\ndef fetch_posts():\n    \"\"\"Extract step: fetch from API with a safe fallback.\"\"\"\n    print(\"[EXTRACT] Fetching posts...\")\n    try:\n        resp = requests.get(API_URL, timeout=15)\n        resp.raise_for_status()\n        data = resp.json()\n        print(\"[EXTRACT] Records:\", len(data))\n        return data\n    except Exception as e:\n        print(\"[EXTRACT] API not reachable, using fallback sample. Error:\", str(e))\n        return [\n            {\"userId\": 1, \"id\": 1, \"title\": \"sample title\", \"body\": \"sample body\"},\n            {\"userId\": 1, \"id\": 2, \"title\": \"another title\", \"body\": \"another body\"},\n        ]\n\ndef save_raw_snapshot(data):\n    \"\"\"Persist raw payload for reproducibility and auditability.\"\"\"\n    ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n    path = RAW_DIR / f\"posts_{ts}.json\"\n    path.write_text(json.dumps(data, indent=2), encoding=\"utf-8\")\n    print(\"[RAW] Snapshot saved:\", path)\n    return path\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Transform\nAdd derived features and apply basic quality checks."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def transform_posts(data):\n    print(\"[TRANSFORM] Building dataframe...\")\n    df = pd.DataFrame(data)\n    print(\"[TRANSFORM] Shape:\", df.shape)\n\n    # Clean strings + derive simple features\n    df[\"title\"] = df[\"title\"].astype(str).str.strip()\n    df[\"body\"] = df[\"body\"].astype(str).str.strip()\n    df[\"title_len\"] = df[\"title\"].str.len()\n    df[\"body_len\"] = df[\"body\"].str.len()\n\n    # Basic data quality checks\n    if df[\"id\"].isna().any():\n        print(\"[DQ] WARNING: null ids detected\")\n    if not df[\"id\"].is_unique:\n        print(\"[DQ] WARNING: duplicate ids detected\")\n    else:\n        print(\"[DQ] id uniqueness OK\")\n\n    return df\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Report\nAggregate by `userId` as a simple decision-support output."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def build_report(df: pd.DataFrame) -> pd.DataFrame:\n    print(\"[REPORT] Building aggregated metrics...\")\n    rep = (\n        df.groupby(\"userId\")\n          .agg(posts=(\"id\", \"count\"),\n               avg_title_len=(\"title_len\", \"mean\"),\n               avg_body_len=(\"body_len\", \"mean\"))\n          .reset_index()\n          .sort_values(\"posts\", ascending=False)\n    )\n    return rep\n\ndef run_api_etl():\n    data = fetch_posts()\n    raw_path = save_raw_snapshot(data)\n\n    df = transform_posts(data)\n    rep = build_report(df)\n\n    print(\"[REPORT] Top users:\")\n    display(rep.head(10))\n\n    print(\"[DONE] Raw snapshot path:\", raw_path)\n    return df, rep\n\ndf, rep = run_api_etl()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}